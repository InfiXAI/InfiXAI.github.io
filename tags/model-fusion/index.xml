<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Model Fusion on InfiX-AI</title>
    <link>http://infixai.github.io/tags/model-fusion/</link>
    <description>Recent content in Model Fusion on InfiX-AI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Jul 2025 11:37:44 +0000</lastBuildDate>
    <atom:link href="http://infixai.github.io/tags/model-fusion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models</title>
      <link>http://infixai.github.io/research/infifpo/</link>
      <pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://infixai.github.io/research/infifpo/</guid>
      <description>&lt;p&gt;We propose &lt;strong&gt;InfiFPO&lt;/strong&gt;, a principled and efficient framework for performing model fusion during the preference alignment phase. Our key insight is that the reference model in preference optimization (e.g., in DPO) can be replaced with a fused source model, thereby enabling the pivot model to learn not only from preference data but also from the probabilistic behaviors of multiple source models.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;assets/exp.png&#34; alt=&#34;InfiFPO&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Comprehensive experiments on 11 widely-used benchmarks demonstrate that &lt;strong&gt;InfiFPO&lt;/strong&gt; consistently outperforms existing model fusion and preference optimization methods. When using Phi-4 as the pivot model, &lt;strong&gt;InfiFPO&lt;/strong&gt; improve its average performance from 79.95 to 83.33 on 11 benchmarks, significantly improving its capabilities in mathematics, coding, and reasoning tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion</title>
      <link>http://infixai.github.io/research/infigfusion/</link>
      <pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://infixai.github.io/research/infigfusion/</guid>
      <description>&lt;p&gt;&lt;strong&gt;InfiGFusion&lt;/strong&gt; is the first structure-aware fusion framework for large language models that models semantic dependencies among logits using feature-level graphs. We introduce a novel Graph-on-Logits Distillation (GLD) loss that captures cross-dimension interactions via co-activation graphs and aligns them using an efficient, provable approximation of Gromov-Wasserstein distance (reducing complexity from O(n^4) to O(nlogn)). Our released &lt;strong&gt;InfiGFusion-14B&lt;/strong&gt; model consistently shows better performance, achieving +35.6 on Multistep Arithmetic and +37.06 on Causal Judgement over SFT, demonstrating superior multi-step and complex logic inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>InfiFPO-14B</title>
      <link>http://infixai.github.io/huggingface.co/InfiX-ai/InfiFPO-14B</link>
      <pubDate>Thu, 31 Jul 2025 11:37:44 +0000</pubDate>
      <guid>http://infixai.github.io/huggingface.co/InfiX-ai/InfiFPO-14B</guid>
      <description></description>
    </item>
    <item>
      <title>InfiFusion-14B</title>
      <link>http://infixai.github.io/huggingface.co/InfiX-ai/InfiFusion-14B</link>
      <pubDate>Thu, 31 Jul 2025 11:37:44 +0000</pubDate>
      <guid>http://infixai.github.io/huggingface.co/InfiX-ai/InfiFusion-14B</guid>
      <description></description>
    </item>
    <item>
      <title>InfiGFusion-14B</title>
      <link>http://infixai.github.io/huggingface.co/InfiX-ai/InfiGFusion-14B</link>
      <pubDate>Thu, 31 Jul 2025 11:37:44 +0000</pubDate>
      <guid>http://infixai.github.io/huggingface.co/InfiX-ai/InfiGFusion-14B</guid>
      <description></description>
    </item>
  </channel>
</rss>
